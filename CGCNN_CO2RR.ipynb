{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66ec6388",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/Users/zach/opt/anaconda3/envs/ml_course/lib/python3.9/site-packages/torch_sparse/_convert_cpu.so, 6): Symbol not found: __ZN2at8internal13_parallel_runExxxRKNSt3__18functionIFvxxmEEE\n  Referenced from: /Users/zach/opt/anaconda3/envs/ml_course/lib/python3.9/site-packages/torch_sparse/_convert_cpu.so\n  Expected in: /Users/zach/opt/anaconda3/envs/ml_course/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib\n in /Users/zach/opt/anaconda3/envs/ml_course/lib/python3.9/site-packages/torch_sparse/_convert_cpu.so",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MessagePassing, global_mean_pool, radius_graph\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mschnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GaussianSmearing\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m  CGConv\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_course/lib/python3.9/site-packages/torch_geometric/__init__.py:7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mseed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m seed_everything\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdebug\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_debug_enabled, debug, set_debug\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mloader\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_course/lib/python3.9/site-packages/torch_geometric/data/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Data\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhetero_data\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HeteroData\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtemporal\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TemporalData\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_course/lib/python3.9/site-packages/torch_geometric/data/data.py:3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (Optional, Dict, Any, Union, List, Iterable, Tuple,\n\u001b[1;32m      2\u001b[0m                     NamedTuple, Callable)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OptTensor, NodeType, EdgeType\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_geometric\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deprecated\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcopy\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_course/lib/python3.9/site-packages/torch_geometric/typing.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tuple, Optional, Union, List\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch_sparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseTensor\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Types for accessing data ####################################################\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Node-types are denoted by a single string, e.g.: `data['paper']`\u001b[39;00m\n\u001b[1;32m      9\u001b[0m NodeType \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_course/lib/python3.9/site-packages/torch_sparse/__init__.py:19\u001b[0m\n\u001b[1;32m     17\u001b[0m spec \u001b[38;5;241m=\u001b[39m cuda_spec \u001b[38;5;129;01mor\u001b[39;00m cpu_spec\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 19\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not find module \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlibrary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_cpu\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mosp\u001b[38;5;241m.\u001b[39mdirname(\u001b[38;5;18m__file__\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_course/lib/python3.9/site-packages/torch/_ops.py:110\u001b[0m, in \u001b[0;36m_Ops.load_library\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    105\u001b[0m path \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils_internal\u001b[38;5;241m.\u001b[39mresolve_library_path(path)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m dl_open_guard():\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;66;03m# Import the shared library into the process, thus running its\u001b[39;00m\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;66;03m# static (global) initialization code in order to register custom\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;66;03m# operators with the JIT.\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m     \u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCDLL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloaded_libraries\u001b[38;5;241m.\u001b[39madd(path)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/ml_course/lib/python3.9/ctypes/__init__.py:374\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FuncPtr \u001b[38;5;241m=\u001b[39m _FuncPtr\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 374\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m \u001b[43m_dlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    376\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/Users/zach/opt/anaconda3/envs/ml_course/lib/python3.9/site-packages/torch_sparse/_convert_cpu.so, 6): Symbol not found: __ZN2at8internal13_parallel_runExxxRKNSt3__18functionIFvxxmEEE\n  Referenced from: /Users/zach/opt/anaconda3/envs/ml_course/lib/python3.9/site-packages/torch_sparse/_convert_cpu.so\n  Expected in: /Users/zach/opt/anaconda3/envs/ml_course/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib\n in /Users/zach/opt/anaconda3/envs/ml_course/lib/python3.9/site-packages/torch_sparse/_convert_cpu.so"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool, radius_graph\n",
    "from torch_geometric.nn.models.schnet import GaussianSmearing\n",
    "from torch_geometric.nn import  CGConv\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "import  sys\n",
    "sys.path.append(\"./\")\n",
    "from AdsorptionSite import *\n",
    "from help_function import *\n",
    "\n",
    "\n",
    "# ## The model\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
    "\n",
    "class CGCNN(torch.nn.Module):\n",
    "    \"\"\"\n",
    "        Initialize CrystalGraphConvNet.\n",
    "        Parameters\n",
    "        ----------\n",
    "        dim_node_attr: int\n",
    "          Number of atom features in the input.\n",
    "        dim_edge_attr: int\n",
    "          Number of edge features in the input.\n",
    "        edges_embedding_size: int\n",
    "          Number of bond features.\n",
    "        atom_embedding_size: int\n",
    "          Number of hidden atom features in the convolutional layers\n",
    "        num_graph_conv_layers: int\n",
    "          Number of convolutional layers\n",
    "        num_fc_layers: int\n",
    "          Number of hidden layers after pooling\n",
    "        fc_feat_size (int, optional):\n",
    "            Size of fully connected layers.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 dim_node_attr,\n",
    "                 dim_edge_attr,\n",
    "                 atom_embedding_size=64,\n",
    "                 edges_embedding_size=128,\n",
    "                 fc_feat_size=128,\n",
    "                 num_graph_conv_layers=6,\n",
    "                 num_fc_layers=4,\n",
    "                 batch_norm=False,\n",
    "                 bias=True):\n",
    "        super(CGCNN, self).__init__()\n",
    "\n",
    "        self.embedding_nodes = torch.nn.Linear(dim_node_attr, atom_embedding_size)\n",
    "\n",
    "        #  Embedding edges features\n",
    "\n",
    "        self.embedding_edges = torch.nn.Linear(dim_edge_attr, edges_embedding_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        self.embedding_fc = torch.nn.Linear(dim_node_attr, atom_embedding_size)\n",
    "\n",
    "        self.convs = nn.ModuleList(\n",
    "            [\n",
    "                CGCNNConv(\n",
    "                    node_dim=atom_embedding_size,\n",
    "                    edge_dim=dim_edge_attr,\n",
    "                )\n",
    "                for _ in range(num_graph_conv_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        self.conv_to_fc = nn.Sequential(\n",
    "            nn.Linear(atom_embedding_size, fc_feat_size), nn.Softplus()\n",
    "        )\n",
    "\n",
    "        if num_fc_layers > 1:\n",
    "            layers = []\n",
    "            for _ in range(num_fc_layers - 1):\n",
    "                layers.append(nn.Linear(fc_feat_size, fc_feat_size))\n",
    "                layers.append(nn.Softplus())\n",
    "            self.fcs = nn.Sequential(*layers)\n",
    "        self.fc_out = nn.Linear(fc_feat_size, 1)\n",
    "\n",
    "\n",
    "    def _forward(self, data):\n",
    "\n",
    "        # Forward pass through the network\n",
    "        mol_feats = self._convolve(data)\n",
    "        mol_feats = self.conv_to_fc(mol_feats)\n",
    "        if hasattr(self, \"fcs\"):\n",
    "            mol_feats = self.fcs(mol_feats)\n",
    "\n",
    "        out = self.fc_out(mol_feats)\n",
    "        return  out.view(-1)\n",
    "\n",
    "    def forward(self, data):\n",
    "\n",
    "        return self._forward(data)\n",
    "\n",
    "\n",
    "\n",
    "    def _convolve(self, data):\n",
    "        \"\"\"\n",
    "        Returns the output of the convolution layers before they are passed\n",
    "        into the dense layers.\n",
    "        \"\"\"\n",
    "        node_feats = self.embedding_nodes(data.x)\n",
    "\n",
    "#         edge_attr = self.embedding_edges(data.edge_attr)\n",
    "\n",
    "        edge_attr = data.edge_attr\n",
    "\n",
    "        for f in self.convs:\n",
    "            node_feats = f(node_feats, data.edge_index, edge_attr )\n",
    "        mol_feats = global_mean_pool(node_feats, data.batch)\n",
    "        return mol_feats\n",
    "\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "class CGCNNConv(MessagePassing):\n",
    "    \"\"\"Implements the message passing layer from\n",
    "    `\"Crystal Graph Convolutional Neural Networks for an\n",
    "    Accurate and Interpretable Prediction of Material Properties\"\n",
    "    <https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.120.145301>`.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, node_dim, edge_dim,  **kwargs):\n",
    "        super(CGCNNConv, self).__init__(aggr=\"add\")\n",
    "        self.node_feat_size = node_dim\n",
    "        self.edge_feat_size = edge_dim\n",
    "\n",
    "        self.lin1 = nn.Linear(\n",
    "            2 * self.node_feat_size + self.edge_feat_size,\n",
    "            2 * self.node_feat_size,\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm1d(2 * self.node_feat_size)\n",
    "        self.ln1 = nn.LayerNorm(self.node_feat_size)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        torch.nn.init.xavier_uniform_(self.lin1.weight)\n",
    "\n",
    "        self.lin1.bias.data.fill_(0)\n",
    "\n",
    "        self.bn1.reset_parameters()\n",
    "        self.ln1.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x has shape [num_nodes, node_feat_size]\n",
    "            edge_index has shape [2, num_edges]\n",
    "            edge_attr is [num_edges, edge_feat_size]\n",
    "        \"\"\"\n",
    "        out = self.propagate(\n",
    "            edge_index, x=x, edge_attr=edge_attr, size=(x.size(0), x.size(0))\n",
    "        )\n",
    "        out = nn.Softplus()(self.ln1(out) + x)\n",
    "        return out\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x_i has shape [num_edges, node_feat_size]\n",
    "            x_j has shape [num_edges, node_feat_size]\n",
    "            edge_attr has shape [num_edges, edge_feat_size]\n",
    "        Returns:\n",
    "            tensor of shape [num_edges, node_feat_size]\n",
    "        \"\"\"\n",
    "        z = self.lin1(torch.cat([x_i, x_j, edge_attr], dim=1))\n",
    "        z = self.bn1(z)\n",
    "        z1, z2 = z.chunk(2, dim=1)\n",
    "        z1 = nn.Sigmoid()(z1)\n",
    "        z2 = nn.Softplus()(z2)\n",
    "        return z1 * z2\n",
    "\n",
    "\n",
    "# ## Plot\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "def plot_train(df, name='trainplot', title=None, x='Target Value', y='Predicted Value', color=None,  hue='adsorbate'):\n",
    "    sns.set_style(\"whitegrid\", {'axes.grid' : False})\n",
    "\n",
    "    actual = df[x].to_numpy()\n",
    "    pred = df[y].to_numpy()\n",
    "    RMSD = np.sqrt( sum( (pred - actual)**2 ) / len(pred) )\n",
    "    MEA = np.mean(np.abs(pred - actual))\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    sns.scatterplot(data=df, x=x, y=y, color=color, hue=hue, s=40,  legend='full', linewidth=0, alpha = 0.7)\n",
    "    sns.lineplot(x=np.linspace(np.amin(actual), np.amax(actual), 100),\n",
    "             y=np.linspace(np.amin(actual), np.amax(actual), 100), color='red')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    at = AnchoredText(\n",
    "        '{:<8s} = {:.3f} eV \\n {:<8s} = {:.3f} eV'.format('RMSD', RMSD, 'MAE', MEA), prop=dict(size=12), frameon=True, loc='upper left')\n",
    "    at.patch.set_boxstyle(\"round,pad=0.,rounding_size=0.2\")\n",
    "    ax.add_artist(at)\n",
    "\n",
    "    ax.legend( title='adsorbate', loc='lower right')\n",
    "    plt.xlabel('$\\Delta E_{DFT}$ [eV]', fontsize=15)\n",
    "    plt.ylabel('$\\Delta E_{Predicted}$ [eV]', fontsize=15)\n",
    "    plt.title(title, fontsize=15)\n",
    "    fig.savefig(name+'.png', dpi=300, transparent=True, bbox_inches='tight')\n",
    "\n",
    "\n",
    "# ## Train  Function\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "def _train(model, loader, epoch,normalizer, optimizer, device='cpu'):\n",
    "    model.train()\n",
    "    loss_all = 0\n",
    "    losses = AverageMeter()\n",
    "    for i, data in enumerate(loader):\n",
    "        target_normed = normalizer.norm(data.y)\n",
    "        target_normed = target_normed.to(device)\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.mse_loss(model(data), target_normed)\n",
    "        loss.backward()\n",
    "#         loss_all += loss.item() * data.num_graphs\n",
    "        losses.update(loss.data.cpu(), data.y.size(0))\n",
    "        optimizer.step()\n",
    "    return losses.avg.item()\n",
    "\n",
    "\n",
    "# ## Test  Function\n",
    "\n",
    "# In[7]:\n",
    "\n",
    "\n",
    "def _test(model, loader, normalizer, device='cpu', test=False):\n",
    "    model.eval()\n",
    "    error = 0\n",
    "    mae_errors = AverageMeter()\n",
    "#     mae_error=0\n",
    "    test_preds = []\n",
    "    test_targets = []\n",
    "    test_idx =[]\n",
    "    test_adsorbate = []\n",
    "\n",
    "#     for i, data in enumerate(tqdm(loader)):\n",
    "    for i, data in enumerate(loader):\n",
    "        data = data.to(device)\n",
    "        pred = model(data)\n",
    "\n",
    "        pred_denormed = normalizer.denorm(pred.data.cpu())\n",
    "        mae_error = mae(pred_denormed, data.y)\n",
    "\n",
    "        mae_errors.update(mae_error, data.y.size(0))\n",
    "        test_preds.extend(pred_denormed.tolist())\n",
    "        test_targets.extend(data.y.tolist())\n",
    "        try:\n",
    "            test_idx.extend(data.idx.tolist())\n",
    "        except:\n",
    "            test_idx.extend(data.idx)\n",
    "        try:\n",
    "            test_adsorbate.extend(data.adsorbate)\n",
    "        except:\n",
    "            test_adsorbate.extend(data.adsorbate)\n",
    "\n",
    "    if test:\n",
    "        my_dict = {\"idx\": test_idx,\n",
    "               \"adsorbate\": test_adsorbate,\n",
    "               'Target Value': test_targets,\n",
    "               'Predicted Value': test_preds}\n",
    "        df = pd.DataFrame(my_dict)\n",
    "        return mae_errors.avg , df\n",
    "    else:\n",
    "        return mae_errors.avg.item()\n",
    "\n",
    "\n",
    "# In[8]:\n",
    "\n",
    "\n",
    "def save_checkpoint(state, is_best, filename, checkpoint_dir='.'):\n",
    "\n",
    "    path = os.path.join(checkpoint_dir, f\"{config['model']}_checkpoint\")\n",
    "    torch.save(state, path)\n",
    "    if is_best:\n",
    "#         bestfile = datetime.now().strftime('Best_NNConv_%d-%m-%y-%H:%m.pth.tar')\n",
    "        bestfile = f\"{config['model']}_best_model\"\n",
    "        shutil.copyfile(path, os.path.join(checkpoint_dir,bestfile))\n",
    "        return bestfile\n",
    "\n",
    "\n",
    "# ## Training\n",
    "\n",
    "# In[9]:\n",
    "\n",
    "\n",
    "def train_function(config, train_dataset, val_dataset,normalizer, device = \"cpu\", checkpoint_dir=None):\n",
    "    best_model = None\n",
    "    best_val_error = 10e15\n",
    "\n",
    "\n",
    "    epoch_history =[]\n",
    "    val_error_history =[]\n",
    "    loss_history =[]\n",
    "\n",
    "\n",
    "    val_loader = DataLoader(val_dataset, batch_size=int(config[\"batch_size\"]), shuffle=True, exclude_keys=['symbol','atomic_number' ,'distance', 'EN' ])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=int(config[\"batch_size\"]), shuffle=True, exclude_keys=['symbol','atomic_number' ,'distance', 'EN' ])\n",
    "\n",
    "    dim_node_attr = train_dataset[0].x.shape[-1]\n",
    "    dim_edge_attr= train_dataset [0].edge_attr.shape[-1]\n",
    "\n",
    "    net = CGCNN(dim_node_attr=dim_node_attr,\n",
    "                 dim_edge_attr=dim_edge_attr,\n",
    "                 atom_embedding_size=config['atom_embedding_size'],\n",
    "                 num_graph_conv_layers=config['num_graph_conv_layers'],\n",
    "                 fc_feat_size=config[\"fc_feat_size\"],\n",
    "                 num_fc_layers=config['num_fc_layers'],\n",
    "                 batch_norm=config['batch_norm'],\n",
    "                 bias=config['bias'])\n",
    "\n",
    "\n",
    "    net.to(device)\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=config[\"lr\"])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min',\n",
    "                                                       factor=0.7, patience=5,\n",
    "                                                       min_lr=0.00001)\n",
    "    for epoch in range(config['Nepoch']):  # loop over the dataset multiple times\n",
    "        lr = scheduler.optimizer.param_groups[0]['lr']\n",
    "\n",
    "\n",
    "\n",
    "        loss = _train(net, train_loader, epoch, normalizer, optimizer, device=device)\n",
    "        val_error = _test(net, val_loader, normalizer)\n",
    "\n",
    "        scheduler.step(val_error)\n",
    "\n",
    "\n",
    "        is_best = val_error < best_val_error\n",
    "\n",
    "        best_val_error = min(val_error , best_val_error)\n",
    "        model_state = {\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"state_dict\": net.state_dict(),\n",
    "                \"best_val_mae\": best_val_error,\n",
    "                \"optimizer\": optimizer.state_dict(),\n",
    "                \"normalizer\": normalizer.state_dict(),\n",
    "                \"criterion\": \"MSELoss\",\n",
    "                \"dim_node_attr\":dim_node_attr,\n",
    "                \"dim_edge_attr\" : dim_edge_attr,\n",
    "                \"atom_embedding_size\": config['atom_embedding_size'],\n",
    "                \"num_fc_layers\" :config['num_fc_layers'],\n",
    "                \"num_graph_conv_layers\": config['num_graph_conv_layers'],\n",
    "                \"fc_feat_size\":config[\"fc_feat_size\"]\n",
    "        }\n",
    "\n",
    "        save_checkpoint(model_state, is_best, f\"{config['model']}_checkpoint\", checkpoint_dir)\n",
    "\n",
    "        epoch_history.append(epoch)\n",
    "        val_error_history.append(val_error)\n",
    "        loss_history.append(loss)\n",
    "        if epoch%50 ==0:\n",
    "            print(f'Epoch: {epoch:04d}, LR: {lr:7f}, Loss: {loss:.7f}, '\n",
    "                  f'Val MAE: {val_error:.7f}')\n",
    "\n",
    "#\n",
    "\n",
    "        if is_best:\n",
    "            best_model = model_state\n",
    "\n",
    "    my_dict = {\"epoch\":epoch_history,\n",
    "                   \"loss\":loss_history ,\n",
    "                   \"val_error\":val_error_history}\n",
    "\n",
    "    df = pd.DataFrame(my_dict)\n",
    "    df = pd.DataFrame(my_dict)\n",
    "    a=config[\"aggr\"]\n",
    "    s=config[\"num_graph_conv_layers\"]\n",
    "    l=config[\"atom_embedding_size\"]\n",
    "    h=config[\"num_fc_layers\"]\n",
    "    b=config[\"fc_feat_size\"]\n",
    "\n",
    "\n",
    "    df.to_csv(f\"{checkpoint_dir}/{config['model']}_{config['emb']}_train_history_{a}_{s}_{l}_{h}_{b}.csv\", index=False)\n",
    "\n",
    "    return best_model\n",
    "\n",
    "\n",
    "# In[10]:\n",
    "\n",
    "\n",
    "def test_best_model(config, test_dataset=None, testfile=None, checkpoint_dir=None, best_model=None, batch_size=8, device=\"cpu\", emb='cgcnn92'):\n",
    "\n",
    "   #     with open('data/raytune_test_data.pickle', 'rb') as handle:\n",
    "#         test_dataset = pickle.load(handle)\n",
    "\n",
    "\n",
    "    if testfile is not None:\n",
    "        with open(testfile, 'rb') as handle:\n",
    "                test_dataset= pickle.load(handle)\n",
    "\n",
    "\n",
    "\n",
    "    if emb != 'cgcnn92':\n",
    "        atom_features =  get_atom_embedding(emb)\n",
    "\n",
    "        for idata, data in enumerate(test_dataset):\n",
    "            node_attr = np.vstack([np.array(atom_features[s]).astype(np.float32) for s in  data.symbol])\n",
    "            test_dataset[idata].x=torch.from_numpy(node_attr)\n",
    "\n",
    "\n",
    "    test_dataset = update_edges(test_dataset)\n",
    "\n",
    "    dim_node_attr =  test_dataset[0].x.shape[-1]\n",
    "    dim_edge_attr= test_dataset[0].edge_attr.shape[-1]\n",
    "\n",
    "\n",
    "\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False,\n",
    "                             exclude_keys=['symbol','atomic_number' ,'distance', 'EN' ])\n",
    "\n",
    "\n",
    "\n",
    "    sample_target = torch.vstack([ data.y for data in test_dataset])\n",
    "    normalizer = Normalizer(sample_target)\n",
    "\n",
    "\n",
    "    if best_model:\n",
    "        model=best_model\n",
    "\n",
    "    else:\n",
    "\n",
    "        best_checkpoint_path = os.path.join(checkpoint_dir, f\"{config['model']}_best_model\")\n",
    "\n",
    "        model = torch.load(best_checkpoint_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    best_trained_model = CGCNN(dim_node_attr=dim_node_attr,\n",
    "                 dim_edge_attr=dim_edge_attr,\n",
    "                 atom_embedding_size=config['atom_embedding_size'],\n",
    "                 num_graph_conv_layers=config['num_graph_conv_layers'],\n",
    "                 fc_feat_size=config[\"fc_feat_size\"],\n",
    "                 num_fc_layers=config['num_fc_layers'],\n",
    "                 batch_norm=config['batch_norm'],\n",
    "                 bias=config['bias'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    best_trained_model.to(device)\n",
    "    normalizer.load_state_dict(model['normalizer'])\n",
    "    best_trained_model.load_state_dict(model['state_dict'])\n",
    "\n",
    "\n",
    "\n",
    "    test_error, test_df  = _test(best_trained_model, test_loader, normalizer,device=device,test=True)\n",
    "\n",
    "\n",
    "\n",
    "    return  test_error, test_df\n",
    "\n",
    "\n",
    "# In[11]:\n",
    "\n",
    "\n",
    "def get_atom_embedding(emb=\"cgcnn92\"):\n",
    "    elem_emb = join(os.path.dirname(os.path.realpath(\"__file__\")),\n",
    "                    f\"element/{emb}.json\")\n",
    "    with open(elem_emb) as f:\n",
    "            atom_features = json.load(f)\n",
    "    return atom_features\n",
    "\n",
    "\n",
    "def update_edges(dataset):\n",
    "    for idata, data in enumerate(dataset):\n",
    "        dataset[idata].edge_attr = torch.stack([1/data.distance[:,0],1/data.EN[:,0]], dim=1).to(torch.float)\n",
    "    return dataset\n",
    "\n",
    "def main(config, datafile, data_size=None, campaign_name=None, train_ratio=None, val_ratio=0.1, test_ratio=0.1, emb=\"cgcnn92\"):\n",
    "\n",
    "\n",
    "    try:\n",
    "        Path(campaign_name).mkdir(parents=True, exist_ok=False)\n",
    "    except FileExistsError:\n",
    "        print(f\"Folder [{campaign_name}] is already there\")\n",
    "    else:\n",
    "        print(f\"Folder [{campaign_name}] was created\")\n",
    "\n",
    "\n",
    "\n",
    "    with open(datafile, 'rb') as handle:\n",
    "        dataset = pickle.load(handle)\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "    \n",
    "#    x = [-2.012450,-2.247770,-2.046270,-2.185180,-2.074820,-2.245050,-1.007220,-2.179560,\n",
    "#    -2.189040,-2.188344,-2.155040,-2.171900,-2.097850,-1.751420]\n",
    "#    #print(len(dataset))\n",
    "#    new = []\n",
    "#    for i in range(len(dataset)):\n",
    "#        if dataset[i].y in x:\n",
    "#            print(i)\n",
    "#        elif dataset[i].y>-1.6:\n",
    "#            print(i)\n",
    "#        else:\n",
    "#            new.append(dataset[i])\n",
    "#    dataset = new\n",
    "    #print(len(dataset),len(new))\n",
    "    #print(len(x))\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "\n",
    "    if data_size is not None:\n",
    "\n",
    "        dataset = random.sample(dataset,  int(len(dataset)*data_size))\n",
    "\n",
    "    if emb != 'cgcnn92':\n",
    "        atom_features =  get_atom_embedding(emb)\n",
    "\n",
    "\n",
    "        for idata, data in enumerate(dataset):\n",
    "            node_attr = np.vstack([np.array(atom_features[s]).astype(np.float32) for s in  data.symbol])\n",
    "            dataset[idata].x=torch.from_numpy(node_attr)\n",
    "\n",
    "\n",
    "    dataset = update_edges(dataset)\n",
    "\n",
    "\n",
    "\n",
    "    train_sampler, val_sampler, test_sampler = get_train_val_test_indices(len(dataset),\n",
    "                                                                          train_ratio=train_ratio,\n",
    "                                                                          val_ratio=val_ratio,\n",
    "                                                                          test_ratio=test_ratio)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    dim_node_attr = dataset[0].x.shape[-1]\n",
    "    dim_edge_attr=dataset[0].edge_attr.shape[-1]\n",
    "\n",
    "    sample_target = torch.vstack([ data.y for data in dataset])\n",
    "    normalizer = Normalizer(sample_target)\n",
    "\n",
    "\n",
    "\n",
    "    train_dataset  = [ dataset[idx] for idx in train_sampler]\n",
    "    val_dataset = [ dataset[idx] for idx in val_sampler]\n",
    "    test_dataset   = [ dataset[idx] for idx in test_sampler]\n",
    "\n",
    "    train_dataset += test_dataset\n",
    "    print('train_sampler len:', len(train_dataset))\n",
    "    print('val_sampler len:', len(val_dataset))\n",
    "\n",
    "\n",
    "    best_model = train_function(config,train_dataset =train_dataset, val_dataset =val_dataset, normalizer=normalizer,checkpoint_dir=campaign_name)\n",
    "\n",
    "    return best_model, test_dataset\n",
    "\n",
    "\n",
    "# ### OH\n",
    "\n",
    "# In[12]:\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    datafile = 'CO2RR/CO2RR_Train_cgcnn92.pickle'\n",
    "    campaign_name = Path(Path(datafile).stem).stem\n",
    "    config = {'lr': 0.0001 ,\n",
    "              'aggr': 'add',\n",
    "              'batch_size':16,\n",
    "                'Nepoch': 500,\n",
    "              \"atom_embedding_size\":64,\n",
    "              \"num_graph_conv_layers\":6,\n",
    "              \"num_fc_layers\":4,\n",
    "              \"fc_feat_size\":128,\n",
    "              \"batch_norm\":True,\n",
    "              \"bias\":True,\n",
    "            \" momentum\": 0.9,\n",
    "            \"weight_decay\":5e-4,\n",
    "            #\"emb\":\"megnet16\",\n",
    "              \"emb\":\"cgcnn92\",\n",
    "            \"model\":'cgcnn'}\n",
    "\n",
    "\n",
    "    a=config[\"aggr\"]\n",
    "    s=config[\"num_graph_conv_layers\"]\n",
    "    l=config[\"atom_embedding_size\"]\n",
    "    h=config[\"num_fc_layers\"]\n",
    "    b=config[\"fc_feat_size\"]\n",
    "\n",
    "\n",
    "    best_model, test_dataset = main(config, datafile, data_size=None, campaign_name=campaign_name, emb=config['emb'])\n",
    "\n",
    "\n",
    "    # In[13]:\n",
    "\n",
    "\n",
    "    train_history = pd.read_csv(f\"{campaign_name}/{config['model']}_{config['emb']}_train_history_{a}_{s}_{l}_{h}_{b}.csv\")\n",
    "    dfm = train_history.melt('epoch', var_name='error_type', value_name='error')\n",
    "    sns.lineplot(data=dfm, x='epoch', y='error',hue='error_type' )\n",
    "    # sns.lineplot(data=train_history,x='epoch', y='val_error', color='r')\n",
    "    # sns.lineplot(data=train_history,x='epoch', y='loss', color='b')\n",
    "\n",
    "\n",
    "    # In[14]:\n",
    "\n",
    "\n",
    "    testfile = 'CO2RR/CO2RR_Test_cgcnn92.pickle'\n",
    "\n",
    "\n",
    "\n",
    "    err, df= test_best_model(config, test_dataset, testfile =testfile,  checkpoint_dir=None, best_model=best_model, batch_size=8, device=\"cpu\",emb=config['emb'])\n",
    "    df.to_csv(f\"{campaign_name}/{config['model']}_{campaign_name}_{config['emb']}_{a}_{s}_{l}_{h}_{b}.csv\", index=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # In[15]:\n",
    "\n",
    "\n",
    "    # df = pd.read_csv(f'results/results_OH.csv')\n",
    "    plot_train(df, name=f\"{campaign_name}/{config['model']}_{campaign_name}_{config['emb']}_{a}_{s}_{l}_{h}_{b}\",  title ='CO/CHO/COOH Parity Plot', x='Target Value', y='Predicted Value', color='b',  hue='adsorbate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4486e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CGCNN92 = 0.123 eV MAE\n",
    "#megnet = 0.116 eV MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9da27261",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CO2RR/CO2RR_Test_cgcnn92.pickle', 'rb') as handle:\n",
    "    dataset = pickle.load(handle)\n",
    "#with open('CO2RR/CO2RR_Train_cgcnn92.pickle', 'rb') as handle:\n",
    "#    dataset = pickle.load(handle)\n",
    "    \n",
    "train_sample\n",
    "r, val_sampler, test_sampler = get_train_val_test_indices(len(dataset),train_ratio=None,\n",
    "                                                                          val_ratio=0.1,\n",
    "                                                                          test_ratio=0.1)        \n",
    "train_dataset  = [ dataset[idx] for idx in train_sampler]\n",
    "val_dataset = [ dataset[idx] for idx in val_sampler]\n",
    "test_dataset   = [ dataset[idx] for idx in test_sampler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38ca98cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "loader = DataLoader(train_dataset, batch_size=1, shuffle=False,\n",
    "                             exclude_keys=['symbol','atomic_number' ,'distance', 'EN' ])\n",
    "\n",
    "for i,data in enumerate(loader):\n",
    "    #print(data.x.shape)\n",
    "    p=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba685ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
